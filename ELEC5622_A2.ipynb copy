{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5622_project2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMMpj82PajhL"
      },
      "source": [
        "#5622 Project2: Hep2_cell classification\n",
        "## 1 Pre-processing\n",
        "### Load image class information file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm_7m0pSBGej"
      },
      "source": [
        "# Importing the dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld77c7AN_x32"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "InfoPath = \"/content/drive/MyDrive/ELEC5622/Project2/gt_training.csv\"\n",
        "\n",
        "classInfo = pd.read_csv(InfoPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmrK5xP-ALtK"
      },
      "source": [
        "# check the image information\n",
        "print(classInfo.dtypes)\n",
        "classInfo['Image ID'] = classInfo['Image ID'].astype('str')\n",
        "print(classInfo.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkflMY4pAWC6"
      },
      "source": [
        "# Check the class distribution\n",
        "classInfo['Image class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jlaiTFA-XV_"
      },
      "source": [
        "### Make class folders for CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE20-f_6AYuO"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "root_path = '/content/drive/MyDrive/ELEC5622/Project2/'\n",
        "old_path = root_path+'Old/'\n",
        "new_path = root_path+'New/'\n",
        "\n",
        "# remove folder if exsits\n",
        "if os.path.exists(new_path):\n",
        "    shutil.rmtree(new_path)\n",
        "\n",
        "for idx,data in classInfo.iterrows():\n",
        "    # training ia mge\n",
        "    old_image = old_path+'training/'+data[0].zfill(5)+'.png'\n",
        "    if os.path.exists(old_image):           \n",
        "        # class folder\n",
        "        new_class = new_path+'training/'+data[1]+'/'\n",
        "        # make folder if not exsits\n",
        "        if not os.path.exists(new_class):\n",
        "              os.makedirs(new_class)\n",
        "        shutil.copy(old_image, new_class)\n",
        "    # validation iamge\n",
        "    old_image = old_path+'validation/'+data[0].zfill(5)+'.png'\n",
        "    if os.path.exists(old_image):           \n",
        "        # class folder\n",
        "        new_class = new_path+'validation/'+data[1]+'/'\n",
        "        # make folder if not exsits\n",
        "        if not os.path.exists(new_class):\n",
        "              os.makedirs(new_class)\n",
        "        shutil.copy(old_image, new_class)\n",
        "    # test iamge\n",
        "    old_image = old_path+'test/'+data[0].zfill(5)+'.png'\n",
        "    if os.path.exists(old_image):           \n",
        "        # class folder\n",
        "        new_class = new_path+'test/'+data[1]+'/'\n",
        "        # make folder if not exsits\n",
        "        if not os.path.exists(new_class):\n",
        "              os.makedirs(new_class)\n",
        "        shutil.copy(old_image, new_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWpRwtwemKan"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "root_path = '/content/drive/MyDrive/悉尼大学/zhuhua/'\n",
        "new_path = root_path+'New/'\n",
        "# get class number\n",
        "classes = glob(new_path+'training/*') \n",
        "# or\n",
        "# classes = ('Centromere','Golgi','Homogeneous','Nucleolar','NuMem','Speckled')\n",
        "print(len(classes))\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQxqcs7gyBhZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OfCGnW5-CTI"
      },
      "source": [
        "### Image normalization & augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNw_khtr9y_8"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# input image size of alexnet\n",
        "image_size = [227,227]\n",
        "\n",
        "data_transform = {\n",
        "    'train':transforms.Compose([\n",
        "                    # horizontal flip\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    # rotation\n",
        "                    transforms.RandomRotation(90),\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    # normalize the image in the range [-1,1]\n",
        "                    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "                    ]),\n",
        "    'validation':transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "                    ]),\n",
        "    'test':transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "                    ])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN0qcjiM98IR"
      },
      "source": [
        "import torch.utils.data\n",
        "\n",
        "def image_preprocess(image_path, transform):\n",
        "    folder = ImageFolder(new_path+image_path,  transform=transform)\n",
        "    loader = torch.utils.data.DataLoader(folder, batch_size=4, shuffle=True, num_workers=2)\n",
        "    return loader\n",
        "\n",
        "train_loader = image_preprocess('training/', data_transform['train'])\n",
        "val_loader = image_preprocess('validation/', data_transform['validation'])\n",
        "test_loader = image_preprocess('test/', data_transform['test'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUuLuO5Gia4G"
      },
      "source": [
        "## 2 AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u4P2T0caEEf"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-if6agwfFdcq"
      },
      "source": [
        "model = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKSES4Ib-RZ"
      },
      "source": [
        "model.classifier = torch.nn.Sequential(nn.Dropout(),\n",
        "                      nn.Linear(256 * 6 * 6, 4096),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.Dropout(),\n",
        "                      nn.Linear(4096, 4096),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.Dropout(0.5),\n",
        "                      nn.Linear(4096, 1000),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.Linear(1000,6))\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3nlStj0cEmR"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "def eval_model(model, dataLoader, accurate_list, datatype):\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in dataLoader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    if datatype == 0:\n",
        "      tra_acc_list.append(100 * correct / total)\n",
        "      print('Accuracy of trainloader: %d %%' % (100 * correct / total))\n",
        "    if datatype == 1:\n",
        "      val_acc_list.append(100 * correct / total)\n",
        "      print('Accuracy of validationloader: %d %%' % (100 * correct / total))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjQewVfWcPzY"
      },
      "source": [
        "classes = ('Centromere','Golgi','Homogeneous','Nucleolar','NuMem','Speckled')\n",
        "\n",
        "tra_acc_list, val_acc_list, loss_list = [], [], []\n",
        "\n",
        "#optimizer and loss\n",
        "import torch.optim as optim\n",
        "lr=0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr,)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=5, verbose=True,\n",
        "        threshold=lr, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
        "\n",
        "#gpu\n",
        "torch.cuda.empty_cache()\n",
        "model=model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrN8UyErcrAO"
      },
      "source": [
        "criterion = criterion.cuda()\n",
        "for state in optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oip6wgl2cxoO"
      },
      "source": [
        "epoch_num=40\n",
        "iteration=10\n",
        "#train process\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    epoch_str = f' Epoch {epoch + 1}/{epoch_num} '\n",
        "    print(f'{epoch_str:-^40s}')\n",
        "    print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data[0].cuda(),data[1].cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % iteration == iteration - 1:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / iteration))\n",
        "            loss_list.append(running_loss / iteration)\n",
        "        running_loss = 0.0\n",
        "    eval_model_train(model, train_loader, tra_acc_list, 0)            \n",
        "    eval_model_validation(model, val_loader, val_acc_list, 1)\n",
        "    scheduler.step(loss.item())\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qeZ-57q1e1v"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuyxhagGYKE7"
      },
      "source": [
        "def show_point(max_id, list):\n",
        "    show_max='['+str(max_id+1)+' '+str(list[max_id])+']'\n",
        "    plt.annotate(show_max, xytext=(max_id+1, list[max_id]), xy=(max_id+1, list[max_id]))\n",
        "    \n",
        "x_acc=[]\n",
        "for i in range(len(tra_acc_list)):\n",
        "    x_acc.append(i+1)\n",
        "\n",
        "x=np.array(x_acc)\n",
        "y1=np.array(tra_acc_list)\n",
        "y2=np.array(val_acc_list)\n",
        "max_tra=np.argmax(y1)\n",
        "max_val=np.argmax(y2)\n",
        "plt.title('Accuracy of Training data and Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Acc(%)')\n",
        "plt.plot(x, y1, label=\"Training\")\n",
        "plt.plot(x, y2, label=\"Validation\")\n",
        "plt.plot(1+max_tra, y1[max_tra], 'r-o')\n",
        "plt.plot(1+max_val, y2[max_val], 'r-o')\n",
        "show_point(max_tra, y1)\n",
        "show_point(max_val, y2)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CCrUoNgcSmw"
      },
      "source": [
        "x_loss=[]\n",
        "for i in range(len(loss_list)):\n",
        "    x_loss.append(i+1)\n",
        "    \n",
        "plt.title('Loss curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x_loss, loss_list)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQU7VLqifg7"
      },
      "source": [
        "## 3 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cc8NLEseTUV"
      },
      "source": [
        "# check the model accuracy on the test data\n",
        "def eval_model_test(model, testLoader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testLoader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of test: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "l_pred_y=[]\n",
        "l_true_y=[]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        l_pred_y.extend(predicted.cpu().numpy())\n",
        "        l_true_y.extend(labels.cpu().numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeG5C0xhewXk"
      },
      "source": [
        "eval_model_test(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445KgVh5mO9N"
      },
      "source": [
        "import seaborn as sn\n",
        "cm = confusion_matrix(l_pred_y, l_true_y)\n",
        "cmn = np.array(cm).astype('float') / np.array(cm).sum(axis=1)[:, np.newaxis]\n",
        "df_cm = pd.DataFrame(cmn, index = [list(classes)], columns = [list(classes)])\n",
        "plt.figure(figsize = (12,6))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}