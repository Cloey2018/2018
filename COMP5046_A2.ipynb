{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSa1rM51HbmZ"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wqZ6PlRJtww"
      },
      "outputs": [],
      "source": [
        "#load model from drive\n",
        "train_id = '1S5RNBF5b1uWbBVjX4NJP0lwZ7NfpzZrA'\n",
        "valid_id = '1zHwLzIVzL_RL_oJiHFp3OYJIGtnPgeZs'\n",
        "test_id = '1-2bYEJViGX-_3FY6so3sTFv1cgjG8SAP'\n",
        "\n",
        "train_downloaded = drive.CreateFile({'id':train_id})\n",
        "train_downloaded.GetContentFile('train.csv')\n",
        "valid_downloaded = drive.CreateFile({'id':valid_id})\n",
        "valid_downloaded.GetContentFile('val.csv')\n",
        "test_downloaded = drive.CreateFile({'id':test_id})\n",
        "test_downloaded.GetContentFile('test_without_labels.csv')\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "valid_data = pd.read_csv('val.csv')\n",
        "test_data = pd.read_csv('test_without_labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfw-YnvFAHJh"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_o-kUzgrW9Z"
      },
      "outputs": [],
      "source": [
        "train_data_sents = train_data['sents'].tolist()\n",
        "train_data_labels = train_data['labels'].tolist()\n",
        "valid_data_sents = valid_data['sents'].tolist()\n",
        "valid_data_labels = valid_data['labels'].tolist()\n",
        "test_data_sents = test_data['sents'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYnSnGwF-UcH",
        "outputId": "9775ee77-1a97-41da-b520-682820a59771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "def split(sentences):\n",
        "  for i in range(len(sentences)):\n",
        "    sentences[i] = sentences[i].split()\n",
        "  return sentences\n",
        "\n",
        "def lower(sentences):\n",
        "  for i in range(len(sentences)):\n",
        "    sentences[i] = [w.lower() for w in sentences[i]]\n",
        "  return sentences\n",
        "\n",
        "train_sents = lower(split(train_data_sents))\n",
        "train_labels = split(train_data_labels)\n",
        "valid_sents = lower(split(valid_data_sents))\n",
        "valid_labels = split(valid_data_labels)\n",
        "test_sents = lower(split(test_data_sents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jFBB2kpss4h"
      },
      "outputs": [],
      "source": [
        "#train word embeddings\n",
        "from gensim.models import Word2Vec\n",
        "import pprint\n",
        "# sentence: iterable of iterables, i.e. the list of lists of tokens from our data\n",
        "# size: dimensionality of the word vectors, window: window size, min_count: ignores all words with total frequency lower than the specified count value\n",
        "# workers: Use specified number of worker threads to train the model (=faster training with multicore machines), sg: training algorithm, 0 for CBOW, 1 for skip-gram\n",
        "concate_data = train_data_sents+valid_data_sents+test_data_sents\n",
        "wv_cbow_model = Word2Vec(sentences=concate_data, size=50, window=4, min_count=0, workers=2, sg=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA4RMVKbE-ES"
      },
      "source": [
        "## PoS tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS8O74seMUxx"
      },
      "outputs": [],
      "source": [
        "#word to index\n",
        "word_to_ix = {}\n",
        "for sentence in train_data_sents+valid_data_sents+test_data_sents:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "#tag to index\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in train_data_labels+valid_data_labels:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQDO63bZfsVi",
        "outputId": "f8a7f711-e376-4053-bfd8-90fb3b745b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Build regular expression tagger using the defined patterns\n",
        "pos_tag = pos_tag(word_to_ix.keys())\n",
        "\n",
        "sentences, sentence_tags =[], []\n",
        "for tagged_sentence in pos_tag:\n",
        "    sentences.append(tagged_sentence[0])\n",
        "    sentence_tags.append(tagged_sentence[1])\n",
        "\n",
        "#pos_tag to index\n",
        "postag_to_ix = {}\n",
        "for tags in sentence_tags:\n",
        "    if tags not in postag_to_ix:\n",
        "        postag_to_ix[tags] = len(postag_to_ix)\n",
        "\n",
        "#word to postag index\n",
        "word_postag = {}\n",
        "for tagged_sentence in pos_tag:\n",
        "    word_postag[tagged_sentence[0]] = postag_to_ix[tagged_sentence[1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYzF0MsyXhQs"
      },
      "source": [
        "##Concate Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDSizO21NruF",
        "outputId": "4a10c052-05cc-4e83-e746-b993fd796e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#load pre-trained word embedding model\n",
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-50\")\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embedding_model_list = list(word_emb_model.vocab.keys())\n",
        "wv_cbow_model_list = list(wv_cbow_model.wv.vocab.keys())\n",
        "intersection=list(set(wv_cbow_model_list) & set(embedding_model_list))\n",
        "\n",
        "embedding_matrix = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in intersection:\n",
        "        embedding_matrix.append(np.concatenate((wv_cbow_model.wv[word],word_emb_model[word]),0))\n",
        "    elif word in wv_cbow_model_list:\n",
        "        embedding_matrix.append(np.concatenate((wv_cbow_model.wv[word],[0]*50),0))\n",
        "\n",
        "embedding_matrix_pos = list(embedding_matrix)\n",
        "for i in range(len(word_list)):\n",
        "    word = word_list[i]\n",
        "    embedding_matrix_pos[i] = np.append(embedding_matrix[i],word_postag[word])\n",
        "\n",
        "embedding_matrix_pos_trained = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in intersection:\n",
        "        embedding_matrix_pos_trained.append(wv_cbow_model.wv[word])\n",
        "    elif word in wv_cbow_model_list:\n",
        "        embedding_matrix_pos_trained.append(wv_cbow_model.wv[word])\n",
        "for i in range(len(word_list)):\n",
        "    word = word_list[i]\n",
        "    embedding_matrix_pos_trained[i] = np.append(embedding_matrix_pos_trained[i],word_postag[word])\n",
        "\n",
        "embedding_matrix_pos_pretrained = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in intersection:\n",
        "        embedding_matrix_pos_pretrained.append(word_emb_model[word])\n",
        "    elif word in wv_cbow_model_list:\n",
        "        embedding_matrix_pos_pretrained.append([0]*50)\n",
        "for i in range(len(word_list)):\n",
        "    word = word_list[i]\n",
        "    embedding_matrix_pos_pretrained[i] = np.append(embedding_matrix_pos_pretrained[i],word_postag[word])\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix_pos = np.array(embedding_matrix_pos)\n",
        "embedding_matrix_pos_trained = np.array(embedding_matrix_pos_trained)\n",
        "embedding_matrix_pos_pretrained = np.array(embedding_matrix_pos_pretrained)\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_emb_model_25 = api.load(\"glove-twitter-25\")\n",
        "\n",
        "embedding_model_25_list = list(word_emb_model_25.vocab.keys())\n",
        "intersection_25=list(set(word_list) & set(embedding_model_25_list))\n",
        "\n",
        "embedding_matrix_25 = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in intersection_25:\n",
        "        embedding_matrix_25.append(word_emb_model_25[word])\n",
        "    elif word in wv_cbow_model_list:\n",
        "        embedding_matrix_25.append([0]*25)\n",
        "\n",
        "embedding_matrix_25 = np.array(embedding_matrix_25)\n",
        "embedding_matrix_25.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKpnrjmErIXr",
        "outputId": "9073f847-41df-4018-cfd8-c6bda5a7037e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezDqgFsDOLKk"
      },
      "outputs": [],
      "source": [
        "#convert dataset into idxs\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data_sents,word_to_ix)\n",
        "train_output_index = to_index(train_data_labels,tag_to_ix)\n",
        "val_input_index = to_index(valid_data_sents,word_to_ix)\n",
        "val_output_index = to_index(valid_data_labels,tag_to_ix)\n",
        "test_input_index = to_index(test_data_sents,word_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbFea67SDdT"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy"
      ],
      "metadata": {
        "id": "zy-4XS5ehnNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Baseline Model"
      ],
      "metadata": {
        "id": "06UYbh-wuE3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF_baseline(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_baseline, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix_25))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "Clnr8TipuJFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_baseline = BiLSTM_CRF_baseline(len(word_to_ix), tag_to_ix, 25, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_baseline.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_baseline.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_baseline.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_baseline.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_baseline.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_baseline,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_baseline,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_baseline.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ativYeEluJrT",
        "outputId": "40713edf-bf99-45ef-bd5c-e1871c97ddb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 32420.53, train acc: 0.9588, val loss: 4751.46, val acc: 0.9582, time: 404.29s\n",
            "Epoch:2, Training loss: 10381.44, train acc: 0.9809, val loss: 2677.46, val acc: 0.9775, time: 398.62s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Classes"
      ],
      "metadata": {
        "id": "RJoq19MJuKZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DotProductAttention"
      ],
      "metadata": {
        "id": "WacTjXegu2nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer: https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class DotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1))\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)  # positions that require masking are now -np.inf\n",
        "        # get attention score\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "vgEJOH3_u9EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CosineAttention"
      ],
      "metadata": {
        "id": "Er2AZKeivCIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer: https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class CosineAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, eps=1e-10, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        q_norm = q / (q.norm(p=2, dim=-1, keepdim=True) + self.eps)  # (B, T_q, D)\n",
        "        k_norm = k / (k.norm(p=2, dim=-1, keepdim=True) + self.eps)  # (B, T_k, D)\n",
        "        attention = torch.bmm(q_norm, k_norm.permute(0, 2, 1))  # (B, T_q, T_k)\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)  # positions that require masking are now -np.inf\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)  # (B, T_q, D_v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "cWyfkw8mvFXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ScaledDotProductAttention"
      ],
      "metadata": {
        "id": "C0hDEqbHvFk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer: https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1))  # (B, T_q, T_k)\n",
        "        # Scale\n",
        "        attention *= k.size(-1) ** -0.5\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)  # positions that require masking are now -np.inf\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)  # (B, T_q, D_v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "cYKs9sw8vI16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+Attention+CRF+PoS+trained"
      ],
      "metadata": {
        "id": "tA1mFaYesTk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF_pos_trained(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_pos_trained, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix_pos_trained))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "tjOMYVtfsXIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_pos_train = BiLSTM_CRF_pos_trained(len(word_to_ix), tag_to_ix, 51, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_pos_train.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "\n",
        "\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_pos_train.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_pos_train.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_pos_train.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_pos_train.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_pos_train,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_pos_train,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_pos_train.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "metadata": {
        "id": "jf0irpu0sqpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f735ea71-83f3-478f-820c-c1cdd614a04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 33021.29, train acc: 0.9856, val loss: 2393.92, val acc: 0.9846, time: 416.20s\n",
            "Epoch:2, Training loss: 4727.78, train acc: 0.9958, val loss: 1328.65, val acc: 0.9932, time: 420.85s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+Attention+CRF+PoS+Pretrained\n"
      ],
      "metadata": {
        "id": "qf2j0--XsGXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF_pos_pretrained(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_pos_pretrained, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix_pos_pretrained))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "we7tNSfMsFJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_pos_pre = BiLSTM_CRF_pos_pretrained(len(word_to_ix), tag_to_ix, 51, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_pos_pre.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "\n",
        "\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    modemodel_pos_prel_pos.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_pos_pre.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_pos_pre.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_pos_pre.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_pos_pre,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_pos_pre,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_pos_pre.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONfApih1zovv",
        "outputId": "260270bc-6ae9-493f-b94d-5143480dfc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 29185.26, train acc: 0.9667, val loss: 3986.87, val acc: 0.9654, time: 417.79s\n",
            "Epoch:2, Training loss: 9119.27, train acc: 0.9839, val loss: 2301.56, val acc: 0.9814, time: 415.25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+Attention+CRF+PoS+Pretrained+trained"
      ],
      "metadata": {
        "id": "lt4bkjrQbelO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd7ZpzITf6GM"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_CRF_pos(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_pos, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix_pos))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLxidcLnX1Z4",
        "outputId": "01ffcb26-7849-489e-d7cc-97d40af20310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 23949.53, train acc: 0.9770, val loss: 3014.85, val acc: 0.9751, time: 519.25s\n",
            "Epoch:2, Training loss: 6813.67, train acc: 0.9892, val loss: 1689.64, val acc: 0.9876, time: 516.95s\n"
          ]
        }
      ],
      "source": [
        "#training model with PoS tag\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_pos = BiLSTM_CRF_pos(len(word_to_ix), tag_to_ix, 101, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_pos.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "\n",
        "\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_pos.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_pos.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_pos.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_pos.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_pos,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_pos,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_pos.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+CRF+one_layer+Pretrained+trained"
      ],
      "metadata": {
        "id": "4hneYGIJemY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw8LjCX7V5m-"
      },
      "outputs": [],
      "source": [
        "#Bi-directional LSTM model\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq95DqM4-wjb",
        "outputId": "49b6be17-7ffa-46e0-f55d-a0419609a078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 22014.71, train acc: 0.9836, val loss: 2309.94, val acc: 0.9828, time: 497.22s\n",
            "Epoch:2, Training loss: 4694.22, train acc: 0.9931, val loss: 1257.81, val acc: 0.9915, time: 490.58s\n"
          ]
        }
      ],
      "source": [
        "#Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_1l = BiLSTM_CRF(len(word_to_ix), tag_to_ix, 100, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_1l.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_1l.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        model_1l.zero_grad()\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_1l.neg_log_likelihood(sentence_in, targets)\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_1l.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_1l,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_1l,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_1l.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+CRF+two_layer"
      ],
      "metadata": {
        "id": "fvol_Z8Wewyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qa4qcbW-waD"
      },
      "outputs": [],
      "source": [
        "#Bi-directional LSTM model with one hidden layer\n",
        "class BiLSTM_CRF_2l(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_2l, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=2, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(4, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(4, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdHHSvyIn8gU",
        "outputId": "56848f2d-7705-4af1-fef5-fb08aabcb581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 31138.78, train acc: 0.9789, val loss: 2795.35, val acc: 0.9773, time: 594.79s\n",
            "Epoch:2, Training loss: 5952.95, train acc: 0.9908, val loss: 1571.02, val acc: 0.9885, time: 592.64s\n"
          ]
        }
      ],
      "source": [
        "#Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_2l = BiLSTM_CRF_2l(len(word_to_ix), tag_to_ix, 100, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_2l.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_2l.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_2l.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_2l.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_2l.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_2l,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_2l,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_2l.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+CRF+3_layer"
      ],
      "metadata": {
        "id": "WgtgzT8Re1QR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taScpa80q6-m"
      },
      "outputs": [],
      "source": [
        "#Bi-directional LSTM model\n",
        "class BiLSTM_CRF_3layers(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_3layers, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=3, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(6, 1, self.hidden_dim // 2),\n",
        "                torch.randn(6, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBTvu0eRtIxU",
        "outputId": "1d5d72e3-2d12-46b6-ace5-053a40065e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 56798.44, train acc: 0.9478, val loss: 6877.08, val acc: 0.9447, time: 663.35s\n",
            "Epoch:2, Training loss: 13151.07, train acc: 0.9807, val loss: 3256.67, val acc: 0.9768, time: 656.23s\n"
          ]
        }
      ],
      "source": [
        "#Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM_1 = 100\n",
        "\n",
        "model_3l = BiLSTM_CRF_3layers(len(word_to_ix), tag_to_ix, 100, HIDDEN_DIM_1).to(device)\n",
        "optimizer = optim.SGD(model_3l.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "import datetime\n",
        "#training model\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_3l.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_3l.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_3l.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_3l.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_3l,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_3l,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_3l.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+Attention+CRF"
      ],
      "metadata": {
        "id": "jsF4ztEre7Hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model"
      ],
      "metadata": {
        "id": "fcIWwCJLyj8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\"\n",
        "ATTN_TYPE_COSINE_SIMILARITY = \"Consine Similarity\"\n",
        "\n",
        "class BiLSTM_Attention_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, method=None):\n",
        "        super(BiLSTM_Attention_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.method = method\n",
        "\n",
        "\n",
        "        if method == ATTN_TYPE_DOT_PRODUCT:\n",
        "            self.attention_layer = DotProductAttention()\n",
        "        elif method == ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "            self.attention_layer = ScaledDotProductAttention()\n",
        "        elif method == ATTN_TYPE_COSINE_SIMILARITY:\n",
        "            self.attention_layer = CosineAttention()\n",
        "        elif method == None:\n",
        "            self.attention_layer = None\n",
        "\n",
        "        if method != None:\n",
        "            self.linear_q = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "            self.linear_k = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "            self.linear_v = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # self.attn = nn.MultiheadAttention(\n",
        "        #     embed_dim=hidden_dim * 2,\n",
        "        #     num_heads=2,\n",
        "        #     dropout=0.0\n",
        "        # )\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.permute(1,0,2)\n",
        "        # (seq_len, batch, num_directions * hidden_size) -->\n",
        "        #(batch, seq_len, num_directions * hidden_size)\n",
        "        if self.attention_layer != None:\n",
        "            # Linear projection\n",
        "            q = self.linear_q(lstm_out)\n",
        "            k = self.linear_k(lstm_out)\n",
        "            v = self.linear_v(lstm_out)\n",
        "            output, attention = self.attention_layer(q,k,v)\n",
        "        else:\n",
        "            output = lstm_out\n",
        "\n",
        "        output = output.view(len(sentence), self.hidden_dim*2)\n",
        "        lstm_feats = self.hidden2tag(output)\n",
        "        return lstm_feats # model : [batch_size, num_classes], attention : [batch_size, n_step]\n",
        "\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "0zDudNGbuMUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "att_model = BiLSTM_Attention_CRF(len(word_to_ix), tag_to_ix, 100, HIDDEN_DIM, \"Dot Product\").to(device)\n",
        "optimizer = optim.SGD(att_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    att_model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        att_model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = att_model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    att_model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(att_model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(att_model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = att_model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZECDOx4uhJf",
        "outputId": "d035ca41-645c-4f69-c738-d98bd5621670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 30831.18, train acc: 0.9772, val loss: 3044.25, val acc: 0.9746, time: 518.08s\n",
            "Epoch:2, Training loss: 6491.73, train acc: 0.9911, val loss: 1574.31, val acc: 0.9883, time: 505.11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CRF"
      ],
      "metadata": {
        "id": "NtueE8EBfW5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####BiLSTM+Attention+withoutCRF"
      ],
      "metadata": {
        "id": "6pKky2BFfYx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM_Attention_noCRF\n",
        "class BiLSTM_Attention_noCRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, method=None):\n",
        "        super(BiLSTM_Attention_noCRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.method = method\n",
        "\n",
        "\n",
        "        if method == ATTN_TYPE_DOT_PRODUCT:\n",
        "            self.attention_layer = DotProductAttention()\n",
        "        elif method == ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "            self.attention_layer = ScaledDotProductAttention()\n",
        "        elif method == ATTN_TYPE_COSINE_SIMILARITY:\n",
        "            self.attention_layer = CosineAttention()\n",
        "        elif method == None:\n",
        "            self.attention_layer = None\n",
        "\n",
        "        if method != None:\n",
        "            self.linear_q = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "            self.linear_k = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "            self.linear_v = nn.Linear(self.hidden_dim*2, self.hidden_dim*2)\n",
        "\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # self.attn = nn.MultiheadAttention(\n",
        "        #     embed_dim=hidden_dim * 2,\n",
        "        #     num_heads=2,\n",
        "        #     dropout=0.0\n",
        "        # )\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.permute(1,0,2)\n",
        "        # (seq_len, batch, num_directions * hidden_size) -->\n",
        "        #(batch, seq_len, num_directions * hidden_size)\n",
        "        if self.attention_layer != None:\n",
        "            # Linear projection\n",
        "            q = self.linear_q(lstm_out)\n",
        "            k = self.linear_k(lstm_out)\n",
        "            v = self.linear_v(lstm_out)\n",
        "            output, attention = self.attention_layer(q,k,v)\n",
        "        else:\n",
        "            output = lstm_out\n",
        "\n",
        "        output = output.view(len(sentence), self.hidden_dim*2)\n",
        "        lstm_feats = self.hidden2tag(output)\n",
        "        return lstm_feats # model : [batch_size, num_classes], attention : [batch_size, n_step]\n",
        "\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        #score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        tag_seq = torch.max(F.softmax(lstm_feats, dim=1), dim=1).indices.tolist()\n",
        "        score = None\n",
        "        return score, tag_seq\n"
      ],
      "metadata": {
        "id": "rkFxT_IgVzvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "model_nocrf = BiLSTM_Attention_noCRF(len(word_to_ix), tag_to_ix, 100, HIDDEN_DIM, \"Dot Product\").to(device)\n",
        "optimizer = optim.SGD(model_nocrf.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_nocrf.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_nocrf.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_nocrf.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model_nocrf.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model_nocrf,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_nocrf,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_nocrf.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFcDtQAnV9Bp",
        "outputId": "839c1975-068b-4c21-f67e-baaa31b31df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 29119.88, train acc: 0.9787, val loss: 2628.40, val acc: 0.9777, time: 487.37s\n",
            "Epoch:2, Training loss: 6319.55, train acc: 0.9875, val loss: 1953.46, val acc: 0.9852, time: 451.55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6mrOuUcCRwJ"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFM4MfLWV8TC"
      },
      "outputs": [],
      "source": [
        "#compute test output list\n",
        "test_output = list()\n",
        "for i, idxs in enumerate(test_input_index):\n",
        "  score, pred = att_model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "  test_output.append(pred)\n",
        "\n",
        "#transform tag to label\n",
        "tag_to_label = {v: k for k, v in tag_to_ix.items()}\n",
        "\n",
        "def to_label(idx,to_label):\n",
        "  input_label_list = []\n",
        "  for sent in idx:\n",
        "    input_label_list.append([to_label[w] for w in sent])\n",
        "  return input_label_list\n",
        "\n",
        "test_output_label = to_label(test_output,tag_to_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC5QVZDFjIIP"
      },
      "outputs": [],
      "source": [
        "#transform to one dimension\n",
        "test_ouput = []\n",
        "for i in test_output_label:\n",
        "  for j in i:\n",
        "    test_ouput.append(j)\n",
        "\n",
        "#reset formality\n",
        "output = pd.DataFrame(test_ouput,columns=['Predicted']).reset_index()\n",
        "output.columns = ['Id','Predicted']\n",
        "output.set_index('Id',inplace=True)\n",
        "output.to_csv('Prediction.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgyvGj2EjGCP"
      },
      "source": [
        "##Evaluation Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEVoaiTqjFZz"
      },
      "outputs": [],
      "source": [
        "#generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def to_label_valid(idx,to_label):\n",
        "    input_label_list = []\n",
        "    for sent in idx:\n",
        "      input_label_list.append(to_label[sent])\n",
        "    return input_label_list\n",
        "\n",
        "def cal_f1(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    true_label = to_label_valid(ground_truth,tag_to_label)\n",
        "    predict_label = to_label_valid(predicted,tag_to_label)\n",
        "    f1_score = classification_report(true_label,predict_label)\n",
        "    return true_label,predict_label,f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvEUzWK6CD3z",
        "outputId": "ad4522b4-6783-4ed3-f55e-8dc602d534b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.98      0.94      0.96      1641\n",
            "           D       0.98      0.82      0.89       398\n",
            "           O       0.98      1.00      0.99     18985\n",
            "           P       0.99      0.99      0.99      3936\n",
            "           S       0.99      0.98      0.99      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.97      0.93      0.95      1469\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.99      0.95      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label_true,prediction,f1 = cal_f1(model_1l,val_input_index,val_output_index)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuI4S4eZOenJ",
        "outputId": "75fbcd41-e0d7-44eb-fd36-944a542d8a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.95      0.95      0.95      1641\n",
            "           D       0.83      0.77      0.80       398\n",
            "           O       0.98      0.99      0.99     18985\n",
            "           P       0.99      0.99      0.99      3936\n",
            "           S       0.99      0.98      0.99      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.96      0.92      0.94      1469\n",
            "\n",
            "    accuracy                           0.98     33354\n",
            "   macro avg       0.96      0.94      0.95     33354\n",
            "weighted avg       0.98      0.98      0.98     33354\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label_true_2l,prediction_2l,f1_2l = cal_f1(model_2l,val_input_index,val_output_index)\n",
        "print(f1_2l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Tdtr_P5GMA",
        "outputId": "2bb3cdec-28b2-4c2d-85c2-cb172b029671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.89      0.93      0.91      1641\n",
            "           D       0.74      0.63      0.68       398\n",
            "           O       0.98      0.99      0.99     18985\n",
            "           P       1.00      0.98      0.99      3936\n",
            "           S       0.99      0.96      0.97      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.95      0.91      0.93      1469\n",
            "\n",
            "    accuracy                           0.98     33354\n",
            "   macro avg       0.93      0.91      0.92     33354\n",
            "weighted avg       0.98      0.98      0.98     33354\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label_true_3l,prediction_3l,f1_3l = cal_f1(model_3l,val_input_index,val_output_index)\n",
        "print(f1_3l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true_pos_pre_tra,prediction_pos_pre_tra,f1_pos_pre_tra = cal_f1(model_pos,val_input_index,val_output_index)\n",
        "print(f1_pos_pre_tra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvFSrU0VHljL",
        "outputId": "4f3caa47-a5bd-4418-ec34-19ec1b02da4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.97      0.94      0.96      1641\n",
            "           D       0.95      0.78      0.86       398\n",
            "           O       0.98      1.00      0.99     18985\n",
            "           P       1.00      0.99      1.00      3936\n",
            "           S       0.99      0.97      0.98      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.99      0.95      0.97      1469\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.99      0.95      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true_att,prediction_att,f1_att = cal_f1(att_model,val_input_index,val_output_index)\n",
        "print(f1_att)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H0UElGwHlUH",
        "outputId": "b9d87eac-8c0f-4d7c-c0de-14343750b4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.98      0.96      0.97      1641\n",
            "           D       0.98      0.80      0.88       398\n",
            "           O       0.99      1.00      0.99     18985\n",
            "           P       1.00      0.99      1.00      3936\n",
            "           S       0.99      0.99      0.99      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.97      0.94      0.96      1469\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.99      0.95      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true_nocrf,prediction_nocrf,f1_nocrf = cal_f1(model_nocrf,val_input_index,val_output_index)\n",
        "print(f1_nocrf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyT4YkgZ1Qwa",
        "outputId": "39394baa-622f-4fd5-ee9b-acbe1cd43931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.94      0.95      0.95      1641\n",
            "           D       0.95      0.70      0.81       398\n",
            "           O       0.99      0.99      0.99     18985\n",
            "           P       1.00      1.00      1.00      3936\n",
            "           S       0.98      0.98      0.98      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.98      0.94      0.96      1469\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.98      0.94      0.95     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true_pos_pre,prediction_pos_pre,f1_pos_pre = cal_f1(model_pos_pre,val_input_index,val_output_index)\n",
        "print(f1_pos_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTzdAKrj08Mg",
        "outputId": "fdc09dfc-c37c-44f1-a6be-1bafda7c296a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.94      0.94      0.94      1641\n",
            "           D       0.94      0.71      0.81       398\n",
            "           O       0.98      0.99      0.98     18985\n",
            "           P       1.00      0.99      0.99      3936\n",
            "           S       0.98      0.96      0.97      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.98      0.94      0.96      1469\n",
            "\n",
            "    accuracy                           0.98     33354\n",
            "   macro avg       0.97      0.93      0.95     33354\n",
            "weighted avg       0.98      0.98      0.98     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true_pos_tra,prediction_pos_tra,f1_pos_tra = cal_f1(model_pos_train,val_input_index,val_output_index)\n",
        "print(f1_pos_tra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYwgtVhs081x",
        "outputId": "14ac9d04-f973-41cf-8b66-a6fc63d5c376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.94      0.93      0.94      1641\n",
            "           D       0.92      0.71      0.80       398\n",
            "           O       0.98      0.99      0.99     18985\n",
            "           P       1.00      0.99      0.99      3936\n",
            "           S       0.98      0.97      0.97      3322\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           T       0.98      0.94      0.96      1469\n",
            "\n",
            "    accuracy                           0.98     33354\n",
            "   macro avg       0.97      0.93      0.95     33354\n",
            "weighted avg       0.98      0.98      0.98     33354\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}