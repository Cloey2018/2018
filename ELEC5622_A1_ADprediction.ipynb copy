{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 117)\n",
      "(10, 117)\n",
      "int64\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "TrainPath = \"AAL_statistics_volumn_train.csv\"\n",
    "TestPath = \"AAL_statistics_volumn_test.csv\"\n",
    "train_raw = pd.read_csv(TrainPath, header = -1)\n",
    "test_raw = pd.read_csv(TestPath, header = -1)\n",
    "\n",
    "# Check wwith the size of dataframe\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "\n",
    "# Check the data type\n",
    "print(train_raw[1].dtypes)\n",
    "print(type(train_raw.iat[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remain the first 90 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_01</td>\n",
       "      <td>4807</td>\n",
       "      <td>4641</td>\n",
       "      <td>5748</td>\n",
       "      <td>6192</td>\n",
       "      <td>2946</td>\n",
       "      <td>3021</td>\n",
       "      <td>8831</td>\n",
       "      <td>9663</td>\n",
       "      <td>2715</td>\n",
       "      <td>...</td>\n",
       "      <td>5842</td>\n",
       "      <td>9606</td>\n",
       "      <td>1876</td>\n",
       "      <td>2398</td>\n",
       "      <td>14654</td>\n",
       "      <td>10655</td>\n",
       "      <td>2072</td>\n",
       "      <td>2784</td>\n",
       "      <td>10591</td>\n",
       "      <td>10289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD_02</td>\n",
       "      <td>5415</td>\n",
       "      <td>6680</td>\n",
       "      <td>5299</td>\n",
       "      <td>6213</td>\n",
       "      <td>1860</td>\n",
       "      <td>1715</td>\n",
       "      <td>7257</td>\n",
       "      <td>10516</td>\n",
       "      <td>1370</td>\n",
       "      <td>...</td>\n",
       "      <td>5331</td>\n",
       "      <td>8316</td>\n",
       "      <td>2650</td>\n",
       "      <td>2970</td>\n",
       "      <td>10744</td>\n",
       "      <td>12238</td>\n",
       "      <td>2684</td>\n",
       "      <td>2417</td>\n",
       "      <td>11016</td>\n",
       "      <td>11556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD_03</td>\n",
       "      <td>4712</td>\n",
       "      <td>6033</td>\n",
       "      <td>5852</td>\n",
       "      <td>5861</td>\n",
       "      <td>2034</td>\n",
       "      <td>2100</td>\n",
       "      <td>8114</td>\n",
       "      <td>6692</td>\n",
       "      <td>2240</td>\n",
       "      <td>...</td>\n",
       "      <td>5399</td>\n",
       "      <td>7249</td>\n",
       "      <td>1450</td>\n",
       "      <td>1002</td>\n",
       "      <td>9615</td>\n",
       "      <td>8012</td>\n",
       "      <td>1315</td>\n",
       "      <td>736</td>\n",
       "      <td>4905</td>\n",
       "      <td>5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_04</td>\n",
       "      <td>6476</td>\n",
       "      <td>5653</td>\n",
       "      <td>6145</td>\n",
       "      <td>6567</td>\n",
       "      <td>2860</td>\n",
       "      <td>3157</td>\n",
       "      <td>9945</td>\n",
       "      <td>9894</td>\n",
       "      <td>2055</td>\n",
       "      <td>...</td>\n",
       "      <td>4348</td>\n",
       "      <td>6020</td>\n",
       "      <td>854</td>\n",
       "      <td>878</td>\n",
       "      <td>9218</td>\n",
       "      <td>12388</td>\n",
       "      <td>288</td>\n",
       "      <td>550</td>\n",
       "      <td>6393</td>\n",
       "      <td>6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD_05</td>\n",
       "      <td>5879</td>\n",
       "      <td>4376</td>\n",
       "      <td>5669</td>\n",
       "      <td>7981</td>\n",
       "      <td>1967</td>\n",
       "      <td>2330</td>\n",
       "      <td>7817</td>\n",
       "      <td>8705</td>\n",
       "      <td>1841</td>\n",
       "      <td>...</td>\n",
       "      <td>5196</td>\n",
       "      <td>6802</td>\n",
       "      <td>1582</td>\n",
       "      <td>1855</td>\n",
       "      <td>12480</td>\n",
       "      <td>9518</td>\n",
       "      <td>1024</td>\n",
       "      <td>1960</td>\n",
       "      <td>7567</td>\n",
       "      <td>8455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7      8     9   ...      81  \\\n",
       "0  AD_01  4807  4641  5748  6192  2946  3021  8831   9663  2715  ...    5842   \n",
       "1  AD_02  5415  6680  5299  6213  1860  1715  7257  10516  1370  ...    5331   \n",
       "2  AD_03  4712  6033  5852  5861  2034  2100  8114   6692  2240  ...    5399   \n",
       "3  AD_04  6476  5653  6145  6567  2860  3157  9945   9894  2055  ...    4348   \n",
       "4  AD_05  5879  4376  5669  7981  1967  2330  7817   8705  1841  ...    5196   \n",
       "\n",
       "     82    83    84     85     86    87    88     89     90  \n",
       "0  9606  1876  2398  14654  10655  2072  2784  10591  10289  \n",
       "1  8316  2650  2970  10744  12238  2684  2417  11016  11556  \n",
       "2  7249  1450  1002   9615   8012  1315   736   4905   5683  \n",
       "3  6020   854   878   9218  12388   288   550   6393   6944  \n",
       "4  6802  1582  1855  12480   9518  1024  1960   7567   8455  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_raw.loc[:, 0:90]\n",
    "test_data = test_raw.loc[:, 0:90]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6757.800000</td>\n",
       "      <td>6538.000000</td>\n",
       "      <td>6913.925000</td>\n",
       "      <td>7653.600000</td>\n",
       "      <td>2323.100000</td>\n",
       "      <td>2523.57500</td>\n",
       "      <td>9725.375000</td>\n",
       "      <td>11243.825000</td>\n",
       "      <td>2276.050000</td>\n",
       "      <td>2907.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>6745.050000</td>\n",
       "      <td>8417.325000</td>\n",
       "      <td>3747.375000</td>\n",
       "      <td>2698.525000</td>\n",
       "      <td>11667.375000</td>\n",
       "      <td>12223.550000</td>\n",
       "      <td>2443.625000</td>\n",
       "      <td>2611.650000</td>\n",
       "      <td>6839.200000</td>\n",
       "      <td>10875.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1687.329314</td>\n",
       "      <td>1531.166691</td>\n",
       "      <td>1533.076083</td>\n",
       "      <td>1810.399726</td>\n",
       "      <td>453.355682</td>\n",
       "      <td>528.81764</td>\n",
       "      <td>2215.264384</td>\n",
       "      <td>2645.460542</td>\n",
       "      <td>561.704912</td>\n",
       "      <td>707.834326</td>\n",
       "      <td>...</td>\n",
       "      <td>2033.848518</td>\n",
       "      <td>2473.698761</td>\n",
       "      <td>2127.877053</td>\n",
       "      <td>1071.603974</td>\n",
       "      <td>2431.797549</td>\n",
       "      <td>3315.054085</td>\n",
       "      <td>1138.699454</td>\n",
       "      <td>1164.723882</td>\n",
       "      <td>1615.244289</td>\n",
       "      <td>3602.719202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3561.000000</td>\n",
       "      <td>3726.000000</td>\n",
       "      <td>4787.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>1537.000000</td>\n",
       "      <td>1715.00000</td>\n",
       "      <td>5912.000000</td>\n",
       "      <td>6692.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1325.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>4025.000000</td>\n",
       "      <td>673.000000</td>\n",
       "      <td>860.000000</td>\n",
       "      <td>6166.000000</td>\n",
       "      <td>6979.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>2920.000000</td>\n",
       "      <td>5167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5390.000000</td>\n",
       "      <td>5614.500000</td>\n",
       "      <td>5642.750000</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>1979.750000</td>\n",
       "      <td>2188.00000</td>\n",
       "      <td>7897.250000</td>\n",
       "      <td>9045.750000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>2424.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>6401.500000</td>\n",
       "      <td>1820.750000</td>\n",
       "      <td>1845.000000</td>\n",
       "      <td>10033.250000</td>\n",
       "      <td>9321.750000</td>\n",
       "      <td>1402.250000</td>\n",
       "      <td>1681.750000</td>\n",
       "      <td>5943.750000</td>\n",
       "      <td>7740.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6835.000000</td>\n",
       "      <td>6496.500000</td>\n",
       "      <td>6753.500000</td>\n",
       "      <td>7779.500000</td>\n",
       "      <td>2236.500000</td>\n",
       "      <td>2548.00000</td>\n",
       "      <td>9896.000000</td>\n",
       "      <td>11647.500000</td>\n",
       "      <td>2243.000000</td>\n",
       "      <td>2753.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>6278.500000</td>\n",
       "      <td>8464.000000</td>\n",
       "      <td>3717.500000</td>\n",
       "      <td>2744.500000</td>\n",
       "      <td>11494.500000</td>\n",
       "      <td>12313.000000</td>\n",
       "      <td>2725.000000</td>\n",
       "      <td>2595.500000</td>\n",
       "      <td>6528.500000</td>\n",
       "      <td>11017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8046.500000</td>\n",
       "      <td>7559.250000</td>\n",
       "      <td>7695.250000</td>\n",
       "      <td>9228.500000</td>\n",
       "      <td>2599.250000</td>\n",
       "      <td>2844.00000</td>\n",
       "      <td>11034.000000</td>\n",
       "      <td>12984.500000</td>\n",
       "      <td>2643.250000</td>\n",
       "      <td>3368.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>8035.000000</td>\n",
       "      <td>10278.250000</td>\n",
       "      <td>5245.000000</td>\n",
       "      <td>3430.750000</td>\n",
       "      <td>12826.500000</td>\n",
       "      <td>15063.250000</td>\n",
       "      <td>3183.500000</td>\n",
       "      <td>3542.750000</td>\n",
       "      <td>7657.500000</td>\n",
       "      <td>13710.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10120.000000</td>\n",
       "      <td>9908.000000</td>\n",
       "      <td>10865.000000</td>\n",
       "      <td>11272.000000</td>\n",
       "      <td>3599.000000</td>\n",
       "      <td>4462.00000</td>\n",
       "      <td>16649.000000</td>\n",
       "      <td>16396.000000</td>\n",
       "      <td>4065.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10976.000000</td>\n",
       "      <td>14364.000000</td>\n",
       "      <td>7641.000000</td>\n",
       "      <td>5023.000000</td>\n",
       "      <td>16640.000000</td>\n",
       "      <td>18311.000000</td>\n",
       "      <td>4684.000000</td>\n",
       "      <td>5057.000000</td>\n",
       "      <td>11016.000000</td>\n",
       "      <td>19792.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1            2             3             4            5   \\\n",
       "count     40.000000    40.000000     40.000000     40.000000    40.000000   \n",
       "mean    6757.800000  6538.000000   6913.925000   7653.600000  2323.100000   \n",
       "std     1687.329314  1531.166691   1533.076083   1810.399726   453.355682   \n",
       "min     3561.000000  3726.000000   4787.000000   3910.000000  1537.000000   \n",
       "25%     5390.000000  5614.500000   5642.750000   6148.000000  1979.750000   \n",
       "50%     6835.000000  6496.500000   6753.500000   7779.500000  2236.500000   \n",
       "75%     8046.500000  7559.250000   7695.250000   9228.500000  2599.250000   \n",
       "max    10120.000000  9908.000000  10865.000000  11272.000000  3599.000000   \n",
       "\n",
       "               6             7             8            9            10  \\\n",
       "count    40.00000     40.000000     40.000000    40.000000    40.000000   \n",
       "mean   2523.57500   9725.375000  11243.825000  2276.050000  2907.950000   \n",
       "std     528.81764   2215.264384   2645.460542   561.704912   707.834326   \n",
       "min    1715.00000   5912.000000   6692.000000  1262.000000  1325.000000   \n",
       "25%    2188.00000   7897.250000   9045.750000  1925.000000  2424.250000   \n",
       "50%    2548.00000   9896.000000  11647.500000  2243.000000  2753.500000   \n",
       "75%    2844.00000  11034.000000  12984.500000  2643.250000  3368.250000   \n",
       "max    4462.00000  16649.000000  16396.000000  4065.000000  4785.000000   \n",
       "\n",
       "           ...                 81            82           83           84  \\\n",
       "count      ...          40.000000     40.000000    40.000000    40.000000   \n",
       "mean       ...        6745.050000   8417.325000  3747.375000  2698.525000   \n",
       "std        ...        2033.848518   2473.698761  2127.877053  1071.603974   \n",
       "min        ...        3888.000000   4025.000000   673.000000   860.000000   \n",
       "25%        ...        5118.000000   6401.500000  1820.750000  1845.000000   \n",
       "50%        ...        6278.500000   8464.000000  3717.500000  2744.500000   \n",
       "75%        ...        8035.000000  10278.250000  5245.000000  3430.750000   \n",
       "max        ...       10976.000000  14364.000000  7641.000000  5023.000000   \n",
       "\n",
       "                 85            86           87           88            89  \\\n",
       "count     40.000000     40.000000    40.000000    40.000000     40.000000   \n",
       "mean   11667.375000  12223.550000  2443.625000  2611.650000   6839.200000   \n",
       "std     2431.797549   3315.054085  1138.699454  1164.723882   1615.244289   \n",
       "min     6166.000000   6979.000000   288.000000   550.000000   2920.000000   \n",
       "25%    10033.250000   9321.750000  1402.250000  1681.750000   5943.750000   \n",
       "50%    11494.500000  12313.000000  2725.000000  2595.500000   6528.500000   \n",
       "75%    12826.500000  15063.250000  3183.500000  3542.750000   7657.500000   \n",
       "max    16640.000000  18311.000000  4684.000000  5057.000000  11016.000000   \n",
       "\n",
       "                 90  \n",
       "count     40.000000  \n",
       "mean   10875.700000  \n",
       "std     3602.719202  \n",
       "min     5167.000000  \n",
       "25%     7740.750000  \n",
       "50%    11017.000000  \n",
       "75%    13710.500000  \n",
       "max    19792.000000  \n",
       "\n",
       "[8 rows x 90 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace AD and NC with 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace AD with value 1\n",
    "train_data.loc[train_data[0].str.contains('AD'), 0] = '1'\n",
    "test_data.loc[test_data[0].str.contains('AD'), 0] = '1'\n",
    "# replace NC with value 0\n",
    "train_data.loc[train_data[0].str.contains('NC'), 0] = '0'\n",
    "test_data.loc[test_data[0].str.contains('NC'), 0] = '0'\n",
    "\n",
    "# Change data type to int\n",
    "train_data[0] = train_data[0].astype('int')\n",
    "test_data[0] = test_data[0].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the the Y/N ratio is the same with original dataset\n",
    "train_AD = train_data.loc[0:19, :]\n",
    "train_NC = train_data.loc[20:39, :]\n",
    "\n",
    "# split X and Y\n",
    "AD_Y = train_AD[0]\n",
    "AD_X = train_AD.drop(0, axis = 1)\n",
    "NC_Y = train_NC[0]\n",
    "NC_X = train_NC.drop(0, axis = 1)\n",
    "Y_test = test_data[0]\n",
    "X_test = test_data.drop(0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "np.random.seed(33)\n",
    "AD_X_train, AD_X_validation, AD_Y_train, AD_Y_validation = train_test_split(AD_X, AD_Y, test_size = 0.2)\n",
    "NC_X_train, NC_X_validation, NC_Y_train, NC_Y_validation = train_test_split(NC_X, NC_Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine AD and NC\n",
    "# AD first to make sure the corresponding labels are correct\n",
    "# train\n",
    "X_train = pd.concat([AD_X_train, NC_X_train])\n",
    "Y_train = pd.concat([AD_Y_train, NC_Y_train])\n",
    "\n",
    "# validation\n",
    "X_validation = pd.concat([AD_X_validation, NC_X_validation])\n",
    "Y_validation = pd.concat([AD_Y_validation, NC_Y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data distribution: 0.50\n",
      "Validation data distribution: 0.50\n",
      "Test data distribution: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Check data distribution in three dataset\n",
    "train_ratio = Y_train.value_counts()[0] / (Y_train.value_counts()[0] + Y_train.value_counts()[1])\n",
    "validation_ratio = Y_validation.value_counts()[0] / (Y_validation.value_counts()[0] + Y_validation.value_counts()[1])\n",
    "test_ratio = Y_test.value_counts()[0] / (Y_test.value_counts()[0] + Y_test.value_counts()[1])\n",
    "print(\"Train data distribution: {:.2f}\\nValidation data distribution: {:.2f}\\nTest data distribution: {:.2f}\"\n",
    "      .format(train_ratio, validation_ratio, test_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing (default value = l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = normalize(X_train)\n",
    "X_validation_norm = normalize(X_validation)\n",
    "X_test_norm = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12875838, 0.15203642, 0.14352994, ..., 0.02295399, 0.09991736,\n",
       "        0.13953325],\n",
       "       [0.09965712, 0.09621566, 0.11916562, ..., 0.05771696, 0.21956908,\n",
       "        0.21330811],\n",
       "       [0.17970488, 0.16993532, 0.15312067, ..., 0.06423142, 0.220682  ,\n",
       "        0.19962928],\n",
       "       ...,\n",
       "       [0.12662853, 0.13006446, 0.12595516, ..., 0.06859765, 0.10430365,\n",
       "        0.20846917],\n",
       "       [0.1006039 , 0.12656018, 0.14617574, ..., 0.0612202 , 0.12664495,\n",
       "        0.23711597],\n",
       "       [0.13265263, 0.14961582, 0.16266609, ..., 0.04568668, 0.11368997,\n",
       "        0.22527297]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "For SVM, we tried different kernel functions to choose the proper one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put classification models in a dictionary\n",
    "models = {'linearSVM' : svm.SVC(kernel = 'linear'),\n",
    "          'polySVM' : svm.SVC(kernel = 'poly'),\n",
    "          'rbfSVM': svm.SVC(kernel = 'rbf'),\n",
    "          'sigmoidSVM': svm.SVC(kernel = 'sigmoid')}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "def fit_and_evaluate(models, X_train_norm, X_validation_norm, Y_train, Y_validation):\n",
    "    np.random.seed(33)\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, Y_train)\n",
    "        model_scores[name] = model.score(X_test, Y_test)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linearSVM': 1.0, 'polySVM': 1.0, 'rbfSVM': 0.5, 'sigmoidSVM': 0.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelScores = fit_and_evaluate(models = models,\n",
    "                                X_train_norm = X_train_norm,\n",
    "                                X_validation_norm = X_validation_norm,\n",
    "                                Y_train = Y_train,\n",
    "                                Y_validation = Y_validation)\n",
    "\n",
    "modelScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select linear and poly as our kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all train and validation to train the model\n",
    "Y_model = train_data[0]\n",
    "X_model = train_data.drop(0, axis = 1)\n",
    "X_model_norm = normalize(X_model)\n",
    "\n",
    "# Train linear and poly SVM\n",
    "SVM_linear = svm.SVC(kernel='linear')\n",
    "SVM_linear.fit(X_model_norm, Y_model)\n",
    "SVM_poly = svm.SVC(kernel='poly')\n",
    "SVM_poly.fit(X_model_norm, Y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of linear SVM and Poly SVM are 1.00 and 1.00 respectively\n"
     ]
    }
   ],
   "source": [
    "acc_linear = SVM_linear.score(X_test_norm, Y_test)\n",
    "acc_poly = SVM_linear.score(X_test_norm, Y_test)\n",
    "print(\"The accuracy of linear SVM and Poly SVM are {:.2f} and {:.2f} respectively\".format(acc_linear, acc_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
