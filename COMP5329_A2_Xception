{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iZd8lZS7Whp"
   },
   "source": [
    "Run codes in  Part1 to adjust parameters and generate a model, codes in Part2 to download our best result to finish prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adg86t526NLA"
   },
   "source": [
    "**Part1**\n",
    "The following codes are to extract data, train and generate required model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ea-BxMDUvhD"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibHVm1wiVix_"
   },
   "outputs": [],
   "source": [
    "id = '1cLKpcZS-P9TCLO0X1xw2p5ZLIwPuzErM'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('test.tar.gz')\n",
    "id = '1ZZ_xgbVMEVuX6NxvpFIk8fWwl5rrvKh0'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train.tar.gz')\n",
    "id = '11opV9N2wI4rcpv5QcsNY2clVgN-IWA7_'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "adAPJKDZWVJd",
    "outputId": "9abbcc60-288f-42f7-9f23-7da0cc0f4753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent 78.424secs\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "tar = tarfile.open(\"train.tar.gz\")\n",
    "names = tar.getnames()\n",
    "for name in names:\n",
    "    tar.extract(name,path=\"/content/\")\n",
    "tar.close()\n",
    "\n",
    "end = time.time()\n",
    "print(\"time spent {}secs\".format(np.round(end-start, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbwvgTPW3_9R"
   },
   "outputs": [],
   "source": [
    "names = names[1:]\n",
    "\n",
    "name_picture = []\n",
    "for name in names:\n",
    "    valid = name.split('/')[1]\n",
    "    name_picture.append(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3TkfYY2bq7x"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "f = open(\"train.txt\")\n",
    "lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    label = line.split()[1]\n",
    "    label = label.split(',')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(int(l))\n",
    "        \n",
    "    labels.append(new_label)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1233
    },
    "colab_type": "code",
    "id": "wjIiWqk4Xg6t",
    "outputId": "8d2c0333-1018-44ed-a8aa-a96ce5c9db4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         picture         label\n",
      "0          0.jpg      [13, 18]\n",
      "1          1.jpg          [19]\n",
      "2          2.jpg          [10]\n",
      "3          3.jpg           [2]\n",
      "4          4.jpg        [8, 7]\n",
      "5          5.jpg          [19]\n",
      "6          6.jpg           [0]\n",
      "7          7.jpg          [19]\n",
      "8          8.jpg      [18, 19]\n",
      "9          9.jpg           [8]\n",
      "10        10.jpg          [18]\n",
      "11        11.jpg           [5]\n",
      "12        12.jpg           [3]\n",
      "13        13.jpg           [9]\n",
      "14        14.jpg          [14]\n",
      "15        15.jpg          [17]\n",
      "16        16.jpg          [11]\n",
      "17        17.jpg      [14, 19]\n",
      "18        18.jpg           [9]\n",
      "19        19.jpg          [17]\n",
      "20        20.jpg           [3]\n",
      "21        21.jpg          [19]\n",
      "22        22.jpg          [11]\n",
      "23        23.jpg       [16, 8]\n",
      "24        24.jpg           [9]\n",
      "25        25.jpg        [6, 9]\n",
      "26        26.jpg           [4]\n",
      "27        27.jpg           [6]\n",
      "28        28.jpg           [8]\n",
      "29        29.jpg           [8]\n",
      "...          ...           ...\n",
      "31895  31895.jpg          [19]\n",
      "31896  31896.jpg          [14]\n",
      "31897  31897.jpg           [9]\n",
      "31898  31898.jpg           [2]\n",
      "31899  31899.jpg           [4]\n",
      "31900  31900.jpg       [7, 16]\n",
      "31901  31901.jpg           [4]\n",
      "31902  31902.jpg          [11]\n",
      "31903  31903.jpg          [14]\n",
      "31904  31904.jpg          [11]\n",
      "31905  31905.jpg        [8, 7]\n",
      "31906  31906.jpg           [6]\n",
      "31907  31907.jpg          [18]\n",
      "31908  31908.jpg           [8]\n",
      "31909  31909.jpg           [6]\n",
      "31910  31910.jpg          [14]\n",
      "31911  31911.jpg      [16, 13]\n",
      "31912  31912.jpg           [6]\n",
      "31913  31913.jpg          [19]\n",
      "31914  31914.jpg          [11]\n",
      "31915  31915.jpg          [19]\n",
      "31916  31916.jpg          [13]\n",
      "31917  31917.jpg           [6]\n",
      "31918  31918.jpg           [3]\n",
      "31919  31919.jpg      [19, 16]\n",
      "31920  31920.jpg           [0]\n",
      "31921  31921.jpg  [18, 19, 11]\n",
      "31922  31922.jpg          [19]\n",
      "31923  31923.jpg      [18, 19]\n",
      "31924  31924.jpg          [16]\n",
      "\n",
      "[31925 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pandas import DataFrame  \n",
    "import pandas as pd   \n",
    "\n",
    "data = {'picture': name_picture, 'label': labels}\n",
    "df = DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71pfNo6lYjSx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8J02IVjkSbe"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def cm_analysis(y_true, y_pred, labels, ymap=None, figsize=(10,10)):\n",
    "    \n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    #plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "ll = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drow(history):\n",
    "    plt.figure(0)\n",
    "    plt.plot(history.history['acc'],'r')\n",
    "    plt.plot(history.history['val_acc'],'g')\n",
    "    plt.xticks(np.arange(0, 20, 1.0))\n",
    "    plt.rcParams['figure.figsize'] = (8,8)\n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "    plt.legend(['train','validation'])\n",
    "    plt.figure(1)\n",
    "    plt.plot(history.history['loss'],'r')\n",
    "    plt.plot(history.history['val_loss'],'g')\n",
    "    plt.xticks(np.arange(0, 20, 1.0))\n",
    "    plt.rcParams['figure.figsize'] = (8,8)\n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss vs Validation Loss\")\n",
    "    plt.legend(['train','validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "dP34vEQ7gPX3",
    "outputId": "9e928307-6c0a-4a9f-d884-a59e15fbc01d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 20 classes.\n",
      "Found 4000 images belonging to 20 classes.\n",
      "Found 3925 images.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)#,rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,horizontal_flip=True, vertical_flip=True,zoom_range=0.2,shear_range=0.2)\n",
    "                          \n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "batch_size = 32\n",
    "img_size = (299,299)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[:24000],\n",
    "directory=\"./train2014\",\n",
    "x_col=\"picture\",\n",
    "y_col=\"label\",\n",
    "batch_size=batch_size,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=img_size)\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[24000:28000],\n",
    "directory=\"./train2014\",\n",
    "x_col=\"picture\",\n",
    "y_col=\"label\",\n",
    "batch_size=batch_size,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=img_size)\n",
    "\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[28000:],\n",
    "directory=\"./train2014\",\n",
    "x_col=\"picture\",\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=img_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMIhK1iphiX8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Flatten\n",
    "\n",
    "base_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(299,299,3), classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAs4nXVn0E37"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, min_delta=1e-2, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p0DvZk1n5rO"
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,kernel_regularizer=regularizers.l2(l=0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256,kernel_regularizer=regularizers.l2(l=0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(20, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4,decay=1e-6), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "o8zTBlBA8ggE",
    "outputId": "c85e2ea9-22ea-4d74-edc7-a908e576bb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 38s 302ms/step - loss: 0.7748 - acc: 0.9606\n",
      "750/750 [==============================] - 1021s 1s/step - loss: 1.2191 - acc: 0.8780 - val_loss: 0.7748 - val_acc: 0.9606\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.3945 - acc: 0.9654\n",
      "750/750 [==============================] - 1014s 1s/step - loss: 0.5657 - acc: 0.9604 - val_loss: 0.3945 - val_acc: 0.9654\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2423 - acc: 0.9657\n",
      "750/750 [==============================] - 1012s 1s/step - loss: 0.2954 - acc: 0.9702 - val_loss: 0.2423 - val_acc: 0.9657\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.1774 - acc: 0.9659\n",
      "750/750 [==============================] - 1014s 1s/step - loss: 0.1735 - acc: 0.9772 - val_loss: 0.1774 - val_acc: 0.9659\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.1589 - acc: 0.9656\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 0.1146 - acc: 0.9820 - val_loss: 0.1589 - val_acc: 0.9656\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.1491 - acc: 0.9656\n",
      "750/750 [==============================] - 1013s 1s/step - loss: 0.0860 - acc: 0.9844 - val_loss: 0.1491 - val_acc: 0.9656\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.1587 - acc: 0.9655\n",
      "750/750 [==============================] - 1014s 1s/step - loss: 0.0688 - acc: 0.9865 - val_loss: 0.1587 - val_acc: 0.9655\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.1669 - acc: 0.9649\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 0.0588 - acc: 0.9879 - val_loss: 0.1669 - val_acc: 0.9649\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.1871 - acc: 0.9673\n",
      "750/750 [==============================] - 1014s 1s/step - loss: 0.0524 - acc: 0.9891 - val_loss: 0.1871 - val_acc: 0.9673\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "sdTHyAaj3lnz",
    "outputId": "8fb367e6-2ca2-4d4c-f0ad-78624ea434de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925/3925 [==============================] - 63s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_generator.n#\n",
    "pred=model.predict_generator(test_generator,steps=STEP_SIZE_TEST,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9iHhebxFZUG-"
   },
   "outputs": [],
   "source": [
    "index = np.argmax(pred,axis=1)\n",
    "correct = 0\n",
    "test = labels[28000:]\n",
    "for i in range(3925):\n",
    "    \n",
    "    if index[i] in test[i]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct/3925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfFU8BvskmMv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "one_hot = MultiLabelBinarizer()\n",
    "test_onehot = one_hot.fit_transform(test)\n",
    "index_onehot = (np.arange(20)==index[:,None]).astype(np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_-u49gEjvUS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,  multi_confusion_matrix\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_onehot.argmax(axis=1), index_onehot.argmax(axis=1)))\n",
    "cr = classification_report(test_onehot.argmax(axis=1), index_onehot.argmax(axis=1))\n",
    "print(\"classification report \\n\",cr)\n",
    "\n",
    "cm_analysis(test_onehot.argmax(axis=1), index_onehot.argmax(axis=1),ll, ymap=None, figsize=(18,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYVPNHK9rYCN"
   },
   "outputs": [],
   "source": [
    "drow(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iZ8HLsS_grN"
   },
   "outputs": [],
   "source": [
    "model.save('last_Xcep_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxLgXacr6Yp7"
   },
   "source": [
    "**Part2** The accuracy of each generated model is different because the parameters are adjusted multiple times, thus here load and call the best model saved during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sasg05y-i2ux"
   },
   "outputs": [],
   "source": [
    "id = '1DFclFBdIKzTmJaYJXmJ1ZNssVcAuhA6w'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Xcep_model_optima.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AGA4NGui2r2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "my_model = load_model('Xcep_model_optima.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_237fID2kNBt"
   },
   "outputs": [],
   "source": [
    "t_tar = tarfile.open(\"test.tar.gz\")\n",
    "t_names = t_tar.getnames()\n",
    "for name in t_names:\n",
    "    t_tar.extract(name,path=\"/content/\")\n",
    "t_tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sku2m_WkM_X"
   },
   "outputs": [],
   "source": [
    "!mkdir output\n",
    "!cp -r ./val2014 ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "L2LORn-HkM8d",
    "outputId": "9e8e7e4f-963a-4ba4-9aa1-c483c755244c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15516 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "prediction_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"./output\",\n",
    "    color_mode = 'rgb',\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=img_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "a87ONEjZml7E",
    "outputId": "d4c3a0f5-7a3c-4d4a-d9bd-aca7f743d0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15516/15516 [==============================] - 557s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_PREDICT = prediction_generator.n // prediction_generator.batch_size\n",
    "\n",
    "prediction_generator.reset()\n",
    "predict = my_model.predict_generator(prediction_generator,steps=STEP_SIZE_PREDICT,verbose=1)\n",
    "\n",
    "predict_index = np.argmax(predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9KDQX2dml3j"
   },
   "outputs": [],
   "source": [
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "outcome = [labels[k] for k in predict_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2XOvCzLml0C"
   },
   "outputs": [],
   "source": [
    "filename = prediction_generator.filenames\n",
    "\n",
    "results = pd.DataFrame({\"Filename\": [file.split('/')[1] for file in filename],\n",
    "                        \"Prediction\":outcome, \n",
    "                        \"Order\":[int(file.split('/')[1].split('.')[0]) for file in filename]})\n",
    "\n",
    "results.sort_values(\"Order\",inplace=True)\n",
    "results.drop([\"Order\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-vHgTtUKMhh"
   },
   "outputs": [],
   "source": [
    "results.to_csv(r\"Predicted_labels.txt\",header=None, index=None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oYlN1KtiPDr"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5329 assignment2 .ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
